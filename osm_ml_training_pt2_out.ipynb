{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011932,
     "end_time": "2019-09-11T05:34:48.381422",
     "exception": false,
     "start_time": "2019-09-11T05:34:48.369490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# AWS Sagemaker Training and Deploying\n",
    "## Cyclone Kenneth 2019-04-25\n",
    "### Part II\n",
    "\n",
    "In this part II notebook, we will upload the data to AWS S3 that we generated for training in the previous notebook. We will kick off an AWS Sagemaker object detection job and monitor the results. At the end of this notebook, you will have trained your own OSM-based CNN object detector!\n",
    "\n",
    "![](assets/happycloud.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.006781,
     "end_time": "2019-09-11T05:34:48.395732",
     "exception": false,
     "start_time": "2019-09-11T05:34:48.388951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Neural Network (Super simplified)\n",
    "\n",
    "We have a bunch of stacked 'neurons' that are mathematical function with weights.\n",
    "\n",
    "The number of neurons and how they are connected to each other defines an 'architecture'.\n",
    "\n",
    "We have a loss function that is iteratively checked to assess whether the neurons (and the weights) are trending to 'good': do the predictions align with the truth (this is validation data)?\n",
    "\n",
    "Weights are defined randomly (typically) to start. The net is pretty dumb. It is through the iterative process of training with many examples that learning is achived through imrpoving the weights.\n",
    "\n",
    "### Goal: Minimize the loss function!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.006214,
     "end_time": "2019-09-11T05:34:48.408241",
     "exception": false,
     "start_time": "2019-09-11T05:34:48.402027",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A couple of things worth noting:\n",
    "\n",
    "ðŸ¤” ML models are not super useful unless they are scaled across a large amount of data\n",
    "\n",
    "ðŸ¤” To effectively scale across data, you need to be efficient\n",
    "\n",
    "ðŸ¤” Because we will be passing sensitive data to this notebook in order to scale our cloud compute through Sagemaker, we will use papermill to run this notebook from within python. It creates a simple wrapper around the notebook so that we can specify variables.\n",
    "\n",
    "e.g.\n",
    "\n",
    "``` python\n",
    "import papermill as pm\n",
    "pm.execute_notebook('osm_ml_training_pt2.ipynb','osm_ml_training_pt2_out.ipynb', parameters = dict(sage_bucket='',my_bucket='', role=''))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 1.219711,
     "end_time": "2019-09-11T05:34:49.634432",
     "exception": false,
     "start_time": "2019-09-11T05:34:48.414721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.006875,
     "end_time": "2019-09-11T05:34:49.647902",
     "exception": false,
     "start_time": "2019-09-11T05:34:49.641027",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will use 'papermill' (https://github.com/nteract/papermill) to pass sensitive variables to this jupyter notebook. Things like passwords, cloud locations, etc, should be paramterized as a best practice -- Never stored in a repo (especially public facing).\n",
    "\n",
    "You will need to run `aws configure --profile uw` and enter in the crednetials I give you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.018171,
     "end_time": "2019-09-11T05:34:49.674671",
     "exception": false,
     "start_time": "2019-09-11T05:34:49.656500",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ACCESS_KEY=''\n",
    "SECRET_KEY=''\n",
    "sage_bucket=''         #this is the 'top-level' s3 bucket, in which you will have a team data-folder\n",
    "my_bucket=''           #this is the 'folder' where your sagemaker data lives\n",
    "prefix = my_bucket     #this is your model prefix\n",
    "sessname =''\n",
    "nclass = 1\n",
    "epochs =50              #number of iterations\n",
    "mini_batch_size =2     #amount of data to use per iteration\n",
    "lr = 0.001\n",
    "lr_scheduler_factor =0.1\n",
    "momentum =0.9\n",
    "weight_decay =0.0005\n",
    "overlap = 0.5\n",
    "momentum = 0.45\n",
    "weight_decay =0.0005\n",
    "nms_thresh = 0.45\n",
    "image_shape =256\n",
    "label_width =600\n",
    "n_train_samples = 16551\n",
    "network ='resnet-50'\n",
    "optim = 'sgd'           #Stochastic gradient descent is an iterative method for optimizing an objective function      \n",
    "role = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.013724,
     "end_time": "2019-09-11T05:34:49.696358",
     "exception": false,
     "start_time": "2019-09-11T05:34:49.682634",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "sage_bucket = \"eagleview-data\"\n",
    "my_bucket = \"team_echidna\"\n",
    "role = \"arn:aws:iam::649760770673:role/service-role/AmazonSageMaker-ExecutionRole-20190910T173949\"\n",
    "ACCESS_KEY = \"AKIAZOSGCRJY5YOTSRPR\"\n",
    "SECRET_KEY = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 5.963178,
     "end_time": "2019-09-11T05:34:55.665953",
     "exception": false,
     "start_time": "2019-09-11T05:34:49.702775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "my_east_sesison = boto3.Session(region_name = 'us-east-2',profile_name='uw')\n",
    "s3_client = my_east_sesison.client(\n",
    "    's3',\n",
    "    aws_access_key_id=ACCESS_KEY,\n",
    "    aws_secret_access_key=SECRET_KEY\n",
    ")\n",
    "s3 = my_east_sesison.resource('s3')\n",
    "\n",
    "s3_client.upload_file('rec/val.rec', sage_bucket, my_bucket+'/validation/val.rec')\n",
    "s3_client.upload_file('rec/train.rec', sage_bucket, my_bucket+'/train/train.rec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.030955,
     "end_time": "2019-09-11T05:34:55.706245",
     "exception": false,
     "start_time": "2019-09-11T05:34:55.675290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.Session(boto_session=my_east_sesison)\n",
    "training_image = get_image_uri(sess.boto_region_name, 'object-detection', repo_version=\"latest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 373.898551,
     "end_time": "2019-09-11T05:41:09.612205",
     "exception": false,
     "start_time": "2019-09-11T05:34:55.713654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-11 05:34:56 Starting - Starting the training job"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-09-11 05:34:57 Starting - Launching requested ML instances"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-09-11 05:36:19 Starting - Preparing the instances for training"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-09-11 05:37:20 Downloading - Downloading input data"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-09-11 05:37:47 Training - Downloading the training image"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-09-11 05:38:34 Training - Training image download completed. Training in progress."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:37 INFO 140277027632960] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/default-input.json: {u'label_width': u'350', u'early_stopping_min_epochs': u'10', u'epochs': u'30', u'overlap_threshold': u'0.5', u'lr_scheduler_factor': u'0.1', u'_num_kv_servers': u'auto', u'weight_decay': u'0.0005', u'mini_batch_size': u'32', u'use_pretrained_model': u'0', u'freeze_layer_pattern': u'', u'lr_scheduler_step': u'', u'early_stopping': u'False', u'early_stopping_patience': u'5', u'momentum': u'0.9', u'num_training_samples': u'', u'optimizer': u'sgd', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.0', u'learning_rate': u'0.001', u'kv_store': u'device', u'nms_threshold': u'0.45', u'num_classes': u'', u'base_network': u'vgg-16', u'nms_topk': u'400', u'_kvstore': u'device', u'image_shape': u'300'}\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:37 INFO 140277027632960] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'0.001', u'epochs': u'50', u'nms_threshold': u'0.45', u'optimizer': u'sgd', u'base_network': u'resnet-50', u'image_shape': u'256', u'label_width': u'600', u'lr_scheduler_step': u'3,6', u'momentum': u'0.45', u'overlap_threshold': u'0.5', u'num_training_samples': u'16551', u'mini_batch_size': u'2', u'weight_decay': u'0.0005', u'use_pretrained_model': u'1', u'num_classes': u'1', u'lr_scheduler_factor': u'0.1'}\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:37 INFO 140277027632960] Final configuration: {u'label_width': u'600', u'early_stopping_min_epochs': u'10', u'epochs': u'50', u'overlap_threshold': u'0.5', u'lr_scheduler_factor': u'0.1', u'_num_kv_servers': u'auto', u'weight_decay': u'0.0005', u'mini_batch_size': u'2', u'use_pretrained_model': u'1', u'freeze_layer_pattern': u'', u'lr_scheduler_step': u'3,6', u'early_stopping': u'False', u'early_stopping_patience': u'5', u'momentum': u'0.45', u'num_training_samples': u'16551', u'optimizer': u'sgd', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.0', u'learning_rate': u'0.001', u'kv_store': u'device', u'nms_threshold': u'0.45', u'num_classes': u'1', u'base_network': u'resnet-50', u'nms_topk': u'400', u'_kvstore': u'device', u'image_shape': u'256'}\u001b[0m\n",
      "\u001b[31mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:37 INFO 140277027632960] Using default worker.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:37 INFO 140277027632960] Loaded iterator creator application/x-image for content type ('application/x-image', '1.0')\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:37 INFO 140277027632960] Loaded iterator creator application/x-recordio for content type ('application/x-recordio', '1.0')\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:37 INFO 140277027632960] Loaded iterator creator image/png for content type ('image/png', '1.0')\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:37 INFO 140277027632960] Loaded iterator creator image/jpeg for content type ('image/jpeg', '1.0')\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:37 INFO 140277027632960] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:37 INFO 140277027632960] nvidia-smi took: 0.025218963623 secs to identify 1 gpus\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:37 INFO 140277027632960] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:37 WARNING 140277027632960] Training images are resized to image shape (3, 256, 256)\u001b[0m\n",
      "\u001b[31m[05:38:37] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-v1.4.1.47.0/AL2012/generic-flavor/src/src/io/iter_image_det_recordio.cc:283: ImageDetRecordIOParser: /opt/ml/input/data/train/train.rec, use 3 threads for decoding..\u001b[0m\n",
      "\u001b[31m[05:38:37] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-v1.4.1.47.0/AL2012/generic-flavor/src/src/io/iter_image_det_recordio.cc:340: ImageDetRecordIOParser: /opt/ml/input/data/train/train.rec, label padding width: 600\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:38 WARNING 140277027632960] Validation images are resized to image shape (3, 256, 256)\u001b[0m\n",
      "\u001b[31m[05:38:38] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-v1.4.1.47.0/AL2012/generic-flavor/src/src/io/iter_image_det_recordio.cc:283: ImageDetRecordIOParser: /opt/ml/input/data/validation/val.rec, use 3 threads for decoding..\u001b[0m\n",
      "\u001b[31m[05:38:38] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-v1.4.1.47.0/AL2012/generic-flavor/src/src/io/iter_image_det_recordio.cc:340: ImageDetRecordIOParser: /opt/ml/input/data/validation/val.rec, label padding width: 600\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:38 INFO 140277027632960] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:38 INFO 140277027632960] Using [gpu(0)] as training context.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:38 INFO 140277027632960] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:38 INFO 140277027632960] Create Store: device\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:38 INFO 140277027632960] Using (gpu(0)) as training context.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:38 INFO 140277027632960] Start training from pretrained model 1.\u001b[0m\n",
      "\u001b[31m[05:38:38] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-v1.4.1.47.0/AL2012/generic-flavor/src/src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\u001b[0m\n",
      "\u001b[31m[05:38:38] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-v1.4.1.47.0/AL2012/generic-flavor/src/src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:39 INFO 140277027632960] Loaded pretrained model parameters.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:43 INFO 140277027632960] Creating a new state instance.\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1568180323.268146, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\"}, \"StartTime\": 1568180323.268028}\n",
      "\u001b[0m\n",
      "\u001b[31m[05:38:43] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-v1.4.1.47.0/AL2012/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[09/11/2019 05:38:54 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:54 INFO 140277027632960] #quality_metric: host=algo-1, epoch=0, batch=10 train cross_entropy <loss>=(0.9417682073812569)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:54 INFO 140277027632960] #quality_metric: host=algo-1, epoch=0, batch=10 train smooth_l1 <loss>=(1.3592917940257925)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:54 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:54 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:54 INFO 140277027632960] #quality_metric: host=algo-1, epoch=0, validation mAP <score>=(0.007122408475943063)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:54 INFO 140277027632960] Updating the best model with validation-mAP=0.007122408475943063\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:54 INFO 140277027632960] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:54 INFO 140277027632960] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1568180334.712641, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 0}, \"StartTime\": 1568180323.268542}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:55 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:55 INFO 140277027632960] #quality_metric: host=algo-1, epoch=1, batch=9 train cross_entropy <loss>=(0.8440356000940851)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:55 INFO 140277027632960] #quality_metric: host=algo-1, epoch=1, batch=9 train smooth_l1 <loss>=(0.8479067974902214)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:55 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:55 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:56 INFO 140277027632960] #quality_metric: host=algo-1, epoch=1, validation mAP <score>=(0.02521890293136608)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:56 INFO 140277027632960] Updating the best model with validation-mAP=0.02521890293136608\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:56 INFO 140277027632960] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:56 INFO 140277027632960] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1568180336.497004, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 1}, \"StartTime\": 1568180334.712931}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:57 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:57 INFO 140277027632960] #quality_metric: host=algo-1, epoch=2, batch=10 train cross_entropy <loss>=(0.8267043856687324)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:57 INFO 140277027632960] #quality_metric: host=algo-1, epoch=2, batch=10 train smooth_l1 <loss>=(1.1582817365956861)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:57 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:57 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:58 INFO 140277027632960] #quality_metric: host=algo-1, epoch=2, validation mAP <score>=(0.016109770801790737)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:58 INFO 140277027632960] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1568180338.398021, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 2}, \"StartTime\": 1568180336.49733}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[09/11/2019 05:38:59 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:59 INFO 140277027632960] #quality_metric: host=algo-1, epoch=3, batch=9 train cross_entropy <loss>=(0.8111637453489666)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:59 INFO 140277027632960] #quality_metric: host=algo-1, epoch=3, batch=9 train smooth_l1 <loss>=(1.3640248503866075)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:59 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:38:59 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:00 INFO 140277027632960] #quality_metric: host=algo-1, epoch=3, validation mAP <score>=(0.02092431031130315)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:00 INFO 140277027632960] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1568180340.110624, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 3}, \"StartTime\": 1568180338.398279}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:01 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:01 INFO 140277027632960] #quality_metric: host=algo-1, epoch=4, batch=10 train cross_entropy <loss>=(0.7880486816656395)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:01 INFO 140277027632960] #quality_metric: host=algo-1, epoch=4, batch=10 train smooth_l1 <loss>=(0.9216530049433473)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:01 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:01 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:02 INFO 140277027632960] #quality_metric: host=algo-1, epoch=4, validation mAP <score>=(0.021628168176386398)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:02 INFO 140277027632960] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1568180342.076598, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 4}, \"StartTime\": 1568180340.110865}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:03 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:03 INFO 140277027632960] #quality_metric: host=algo-1, epoch=5, batch=9 train cross_entropy <loss>=(0.804035518850599)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:03 INFO 140277027632960] #quality_metric: host=algo-1, epoch=5, batch=9 train smooth_l1 <loss>=(0.9314336563859668)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:03 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:03 INFO 140277027632960] Updated the metrics\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[09/11/2019 05:39:03 INFO 140277027632960] #quality_metric: host=algo-1, epoch=5, validation mAP <score>=(0.009521666973255)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:03 INFO 140277027632960] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1568180343.700893, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 5}, \"StartTime\": 1568180342.076891}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:05 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:05 INFO 140277027632960] #quality_metric: host=algo-1, epoch=6, batch=10 train cross_entropy <loss>=(0.774077676591419)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:05 INFO 140277027632960] #quality_metric: host=algo-1, epoch=6, batch=10 train smooth_l1 <loss>=(0.8594154516855875)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:05 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:05 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:05 INFO 140277027632960] #quality_metric: host=algo-1, epoch=6, validation mAP <score>=(0.0061319351010225625)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:05 INFO 140277027632960] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1568180345.585512, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 6}, \"StartTime\": 1568180343.701127}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:06 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:06 INFO 140277027632960] #quality_metric: host=algo-1, epoch=7, batch=9 train cross_entropy <loss>=(0.7789453546577525)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:06 INFO 140277027632960] #quality_metric: host=algo-1, epoch=7, batch=9 train smooth_l1 <loss>=(0.9993230427537009)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:06 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:06 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:07 INFO 140277027632960] #quality_metric: host=algo-1, epoch=7, validation mAP <score>=(0.006675191569459726)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:07 INFO 140277027632960] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1568180347.216141, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 7}, \"StartTime\": 1568180345.58575}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:08 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:08 INFO 140277027632960] #quality_metric: host=algo-1, epoch=8, batch=10 train cross_entropy <loss>=(0.8019576569398245)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:08 INFO 140277027632960] #quality_metric: host=algo-1, epoch=8, batch=10 train smooth_l1 <loss>=(0.9906660159428914)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:08 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:08 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:09 INFO 140277027632960] #quality_metric: host=algo-1, epoch=8, validation mAP <score>=(0.011330479122951107)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:09 INFO 140277027632960] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1568180349.029119, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 8}, \"StartTime\": 1568180347.216419}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:10 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:10 INFO 140277027632960] #quality_metric: host=algo-1, epoch=9, batch=9 train cross_entropy <loss>=(0.7851886727394314)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:10 INFO 140277027632960] #quality_metric: host=algo-1, epoch=9, batch=9 train smooth_l1 <loss>=(0.7900619988047749)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:10 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:10 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:10 INFO 140277027632960] #quality_metric: host=algo-1, epoch=9, validation mAP <score>=(0.03826276705379426)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:10 INFO 140277027632960] Updating the best model with validation-mAP=0.03826276705379426\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:10 INFO 140277027632960] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:10 INFO 140277027632960] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1568180350.794024, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 9}, \"StartTime\": 1568180349.029345}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:12 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:12 INFO 140277027632960] #quality_metric: host=algo-1, epoch=10, batch=10 train cross_entropy <loss>=(0.7647726226735998)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:12 INFO 140277027632960] #quality_metric: host=algo-1, epoch=10, batch=10 train smooth_l1 <loss>=(0.9873778025309244)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:12 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:12 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:12 INFO 140277027632960] #quality_metric: host=algo-1, epoch=10, validation mAP <score>=(0.0059205642372066)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:12 INFO 140277027632960] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}}, \"EndTime\": 1568180352.633641, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 10}, \"StartTime\": 1568180350.79472}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[09/11/2019 05:39:13 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:13 INFO 140277027632960] #quality_metric: host=algo-1, epoch=11, batch=9 train cross_entropy <loss>=(0.7663869636574971)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:13 INFO 140277027632960] #quality_metric: host=algo-1, epoch=11, batch=9 train smooth_l1 <loss>=(0.6520126701630268)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:13 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:13 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:14 INFO 140277027632960] #quality_metric: host=algo-1, epoch=11, validation mAP <score>=(0.016914574133555422)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:14 INFO 140277027632960] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}}, \"EndTime\": 1568180354.191461, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 11}, \"StartTime\": 1568180352.633913}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:15 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:15 INFO 140277027632960] #quality_metric: host=algo-1, epoch=12, batch=10 train cross_entropy <loss>=(0.7685179750124613)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:15 INFO 140277027632960] #quality_metric: host=algo-1, epoch=12, batch=10 train smooth_l1 <loss>=(0.7467535714308421)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:15 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:15 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:16 INFO 140277027632960] #quality_metric: host=algo-1, epoch=12, validation mAP <score>=(0.006941340998509017)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:16 INFO 140277027632960] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 13, \"sum\": 13.0, \"min\": 13}}, \"EndTime\": 1568180356.123971, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 12}, \"StartTime\": 1568180354.191722}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:17 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:17 INFO 140277027632960] #quality_metric: host=algo-1, epoch=13, batch=9 train cross_entropy <loss>=(0.7820955781794307)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:17 INFO 140277027632960] #quality_metric: host=algo-1, epoch=13, batch=9 train smooth_l1 <loss>=(1.0370970555205843)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:17 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:17 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:17 INFO 140277027632960] #quality_metric: host=algo-1, epoch=13, validation mAP <score>=(0.010883069601138804)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:17 INFO 140277027632960] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 14, \"sum\": 14.0, \"min\": 14}}, \"EndTime\": 1568180357.714305, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 13}, \"StartTime\": 1568180356.124234}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:19 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:19 INFO 140277027632960] #quality_metric: host=algo-1, epoch=14, batch=10 train cross_entropy <loss>=(0.7727651767902546)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:19 INFO 140277027632960] #quality_metric: host=algo-1, epoch=14, batch=10 train smooth_l1 <loss>=(1.0032424969716116)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:19 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:19 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:19 INFO 140277027632960] #quality_metric: host=algo-1, epoch=14, validation mAP <score>=(0.012431667235721342)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:19 INFO 140277027632960] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}}, \"EndTime\": 1568180359.557115, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 14}, \"StartTime\": 1568180357.71454}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:20 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:20 INFO 140277027632960] #quality_metric: host=algo-1, epoch=15, batch=9 train cross_entropy <loss>=(0.7764521222561598)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:20 INFO 140277027632960] #quality_metric: host=algo-1, epoch=15, batch=9 train smooth_l1 <loss>=(0.8146730549633503)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:20 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:20 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:21 INFO 140277027632960] #quality_metric: host=algo-1, epoch=15, validation mAP <score>=(0.014196386664895963)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:21 INFO 140277027632960] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 16, \"sum\": 16.0, \"min\": 16}}, \"EndTime\": 1568180361.218077, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 15}, \"StartTime\": 1568180359.557428}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:22 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:22 INFO 140277027632960] #quality_metric: host=algo-1, epoch=16, batch=10 train cross_entropy <loss>=(0.7750378388624924)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:22 INFO 140277027632960] #quality_metric: host=algo-1, epoch=16, batch=10 train smooth_l1 <loss>=(0.9468552067748501)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:22 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:22 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:23 INFO 140277027632960] #quality_metric: host=algo-1, epoch=16, validation mAP <score>=(0.03588127951599974)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:23 INFO 140277027632960] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 17, \"sum\": 17.0, \"min\": 17}}, \"EndTime\": 1568180363.056084, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 16}, \"StartTime\": 1568180361.218306}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[09/11/2019 05:39:24 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:24 INFO 140277027632960] #quality_metric: host=algo-1, epoch=17, batch=9 train cross_entropy <loss>=(0.7644274594291808)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:24 INFO 140277027632960] #quality_metric: host=algo-1, epoch=17, batch=9 train smooth_l1 <loss>=(0.7978552674490308)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:24 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:24 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:24 INFO 140277027632960] #quality_metric: host=algo-1, epoch=17, validation mAP <score>=(0.008188251692166889)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:24 INFO 140277027632960] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 18, \"sum\": 18.0, \"min\": 18}}, \"EndTime\": 1568180364.59351, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 17}, \"StartTime\": 1568180363.056308}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:25 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:25 INFO 140277027632960] #quality_metric: host=algo-1, epoch=18, batch=10 train cross_entropy <loss>=(0.7513975444592927)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:25 INFO 140277027632960] #quality_metric: host=algo-1, epoch=18, batch=10 train smooth_l1 <loss>=(0.9250770518654271)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:25 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:25 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:26 INFO 140277027632960] #quality_metric: host=algo-1, epoch=18, validation mAP <score>=(0.01073422489370828)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:26 INFO 140277027632960] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 19, \"sum\": 19.0, \"min\": 19}}, \"EndTime\": 1568180366.446971, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 18}, \"StartTime\": 1568180364.593756}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:27 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:27 INFO 140277027632960] #quality_metric: host=algo-1, epoch=19, batch=9 train cross_entropy <loss>=(0.7639753303012332)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:27 INFO 140277027632960] #quality_metric: host=algo-1, epoch=19, batch=9 train smooth_l1 <loss>=(0.9709647539499644)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:27 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:27 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:28 INFO 140277027632960] #quality_metric: host=algo-1, epoch=19, validation mAP <score>=(0.011083200812843126)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:28 INFO 140277027632960] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 20, \"sum\": 20.0, \"min\": 20}}, \"EndTime\": 1568180368.007062, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 19}, \"StartTime\": 1568180366.447319}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:29 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:29 INFO 140277027632960] #quality_metric: host=algo-1, epoch=20, batch=10 train cross_entropy <loss>=(0.7612304399753439)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:29 INFO 140277027632960] #quality_metric: host=algo-1, epoch=20, batch=10 train smooth_l1 <loss>=(0.8789862969826008)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:29 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:29 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:29 INFO 140277027632960] #quality_metric: host=algo-1, epoch=20, validation mAP <score>=(0.022883391216195873)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:29 INFO 140277027632960] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 21, \"sum\": 21.0, \"min\": 21}}, \"EndTime\": 1568180369.83954, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 20}, \"StartTime\": 1568180368.007292}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:30 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:30 INFO 140277027632960] #quality_metric: host=algo-1, epoch=21, batch=9 train cross_entropy <loss>=(0.7586182255611241)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:30 INFO 140277027632960] #quality_metric: host=algo-1, epoch=21, batch=9 train smooth_l1 <loss>=(0.9029327642137759)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:30 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:31 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:31 INFO 140277027632960] #quality_metric: host=algo-1, epoch=21, validation mAP <score>=(0.015837195265604242)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:31 INFO 140277027632960] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}}, \"EndTime\": 1568180371.495949, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 21}, \"StartTime\": 1568180369.840025}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:32 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:32 INFO 140277027632960] #quality_metric: host=algo-1, epoch=22, batch=10 train cross_entropy <loss>=(0.7634649156319975)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:32 INFO 140277027632960] #quality_metric: host=algo-1, epoch=22, batch=10 train smooth_l1 <loss>=(1.0240590644605232)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:32 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:32 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:33 INFO 140277027632960] #quality_metric: host=algo-1, epoch=22, validation mAP <score>=(0.02248751333878298)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:33 INFO 140277027632960] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 23, \"sum\": 23.0, \"min\": 23}}, \"EndTime\": 1568180373.328462, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 22}, \"StartTime\": 1568180371.496195}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:34 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:34 INFO 140277027632960] #quality_metric: host=algo-1, epoch=23, batch=9 train cross_entropy <loss>=(0.7630364052180586)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:34 INFO 140277027632960] #quality_metric: host=algo-1, epoch=23, batch=9 train smooth_l1 <loss>=(0.8552432224668306)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:34 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:34 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:34 INFO 140277027632960] #quality_metric: host=algo-1, epoch=23, validation mAP <score>=(0.023697830696305044)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:34 INFO 140277027632960] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 24, \"sum\": 24.0, \"min\": 24}}, \"EndTime\": 1568180374.970609, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 23}, \"StartTime\": 1568180373.328705}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:36 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:36 INFO 140277027632960] #quality_metric: host=algo-1, epoch=24, batch=10 train cross_entropy <loss>=(0.7557420900889805)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:36 INFO 140277027632960] #quality_metric: host=algo-1, epoch=24, batch=10 train smooth_l1 <loss>=(0.8802203933397929)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:36 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:36 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:36 INFO 140277027632960] #quality_metric: host=algo-1, epoch=24, validation mAP <score>=(0.03013338271344735)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:36 INFO 140277027632960] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 25, \"sum\": 25.0, \"min\": 25}}, \"EndTime\": 1568180376.876359, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 24}, \"StartTime\": 1568180374.970885}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:37 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:37 INFO 140277027632960] #quality_metric: host=algo-1, epoch=25, batch=9 train cross_entropy <loss>=(0.7535948508253721)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:37 INFO 140277027632960] #quality_metric: host=algo-1, epoch=25, batch=9 train smooth_l1 <loss>=(0.8944193670682818)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:37 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:38 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:38 INFO 140277027632960] #quality_metric: host=algo-1, epoch=25, validation mAP <score>=(0.049402555515138086)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:38 INFO 140277027632960] Updating the best model with validation-mAP=0.049402555515138086\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:38 INFO 140277027632960] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:38 INFO 140277027632960] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 26, \"sum\": 26.0, \"min\": 26}}, \"EndTime\": 1568180378.642887, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 25}, \"StartTime\": 1568180376.876816}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[09/11/2019 05:39:39 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:39 INFO 140277027632960] #quality_metric: host=algo-1, epoch=26, batch=10 train cross_entropy <loss>=(0.7620755615880934)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:39 INFO 140277027632960] #quality_metric: host=algo-1, epoch=26, batch=10 train smooth_l1 <loss>=(0.9095835604910123)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:39 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:40 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:40 INFO 140277027632960] #quality_metric: host=algo-1, epoch=26, validation mAP <score>=(0.015967914094507214)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:40 INFO 140277027632960] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 27, \"sum\": 27.0, \"min\": 27}}, \"EndTime\": 1568180380.471475, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 26}, \"StartTime\": 1568180378.643212}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:41 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:41 INFO 140277027632960] #quality_metric: host=algo-1, epoch=27, batch=9 train cross_entropy <loss>=(0.7512233718749015)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:41 INFO 140277027632960] #quality_metric: host=algo-1, epoch=27, batch=9 train smooth_l1 <loss>=(0.8254839502355104)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:41 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:41 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:42 INFO 140277027632960] #quality_metric: host=algo-1, epoch=27, validation mAP <score>=(0.03831901273814081)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:42 INFO 140277027632960] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 28, \"sum\": 28.0, \"min\": 28}}, \"EndTime\": 1568180382.087707, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 27}, \"StartTime\": 1568180380.472779}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:43 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:43 INFO 140277027632960] #quality_metric: host=algo-1, epoch=28, batch=10 train cross_entropy <loss>=(0.7636561212868526)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:43 INFO 140277027632960] #quality_metric: host=algo-1, epoch=28, batch=10 train smooth_l1 <loss>=(0.8725328330335946)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:43 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:43 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:43 INFO 140277027632960] #quality_metric: host=algo-1, epoch=28, validation mAP <score>=(0.02306553223402968)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:43 INFO 140277027632960] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 29, \"sum\": 29.0, \"min\": 29}}, \"EndTime\": 1568180383.904264, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 28}, \"StartTime\": 1568180382.087935}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:44 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:44 INFO 140277027632960] #quality_metric: host=algo-1, epoch=29, batch=9 train cross_entropy <loss>=(0.7467360846493223)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:44 INFO 140277027632960] #quality_metric: host=algo-1, epoch=29, batch=9 train smooth_l1 <loss>=(0.8523919822972849)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:44 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:45 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:45 INFO 140277027632960] #quality_metric: host=algo-1, epoch=29, validation mAP <score>=(0.018173938037431527)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:45 INFO 140277027632960] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 30, \"sum\": 30.0, \"min\": 30}}, \"EndTime\": 1568180385.507153, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 29}, \"StartTime\": 1568180383.904577}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:46 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:46 INFO 140277027632960] #quality_metric: host=algo-1, epoch=30, batch=10 train cross_entropy <loss>=(0.7635127583840736)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:46 INFO 140277027632960] #quality_metric: host=algo-1, epoch=30, batch=10 train smooth_l1 <loss>=(0.94791519193721)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:46 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:46 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:47 INFO 140277027632960] #quality_metric: host=algo-1, epoch=30, validation mAP <score>=(0.015106376992592246)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:47 INFO 140277027632960] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}}, \"EndTime\": 1568180387.343409, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 30}, \"StartTime\": 1568180385.507395}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:48 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:48 INFO 140277027632960] #quality_metric: host=algo-1, epoch=31, batch=9 train cross_entropy <loss>=(0.7439708372132968)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:48 INFO 140277027632960] #quality_metric: host=algo-1, epoch=31, batch=9 train smooth_l1 <loss>=(0.7858681678771973)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:48 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:48 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:48 INFO 140277027632960] #quality_metric: host=algo-1, epoch=31, validation mAP <score>=(0.03419425719261233)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:48 INFO 140277027632960] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 32, \"sum\": 32.0, \"min\": 32}}, \"EndTime\": 1568180388.935627, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 31}, \"StartTime\": 1568180387.343674}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[09/11/2019 05:39:50 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:50 INFO 140277027632960] #quality_metric: host=algo-1, epoch=32, batch=10 train cross_entropy <loss>=(0.7492496317083185)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:50 INFO 140277027632960] #quality_metric: host=algo-1, epoch=32, batch=10 train smooth_l1 <loss>=(0.7660203472641874)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:50 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:50 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:50 INFO 140277027632960] #quality_metric: host=algo-1, epoch=32, validation mAP <score>=(0.03994922693949471)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:50 INFO 140277027632960] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 33, \"sum\": 33.0, \"min\": 33}}, \"EndTime\": 1568180390.788492, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 32}, \"StartTime\": 1568180388.935941}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:51 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:51 INFO 140277027632960] #quality_metric: host=algo-1, epoch=33, batch=9 train cross_entropy <loss>=(0.7294909364169406)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:51 INFO 140277027632960] #quality_metric: host=algo-1, epoch=33, batch=9 train smooth_l1 <loss>=(0.885694170735546)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:51 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:52 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:52 INFO 140277027632960] #quality_metric: host=algo-1, epoch=33, validation mAP <score>=(0.01885555532195515)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:52 INFO 140277027632960] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 34, \"sum\": 34.0, \"min\": 34}}, \"EndTime\": 1568180392.406636, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 33}, \"StartTime\": 1568180390.789027}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:53 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:53 INFO 140277027632960] #quality_metric: host=algo-1, epoch=34, batch=10 train cross_entropy <loss>=(0.7475791882424458)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:53 INFO 140277027632960] #quality_metric: host=algo-1, epoch=34, batch=10 train smooth_l1 <loss>=(0.8986476424836765)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:53 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:53 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:54 INFO 140277027632960] #quality_metric: host=algo-1, epoch=34, validation mAP <score>=(0.022819208898225807)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:54 INFO 140277027632960] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 35, \"sum\": 35.0, \"min\": 35}}, \"EndTime\": 1568180394.205267, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 34}, \"StartTime\": 1568180392.40688}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:55 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:55 INFO 140277027632960] #quality_metric: host=algo-1, epoch=35, batch=9 train cross_entropy <loss>=(0.7423390533964512)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:55 INFO 140277027632960] #quality_metric: host=algo-1, epoch=35, batch=9 train smooth_l1 <loss>=(0.8563211125842596)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:55 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:55 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:55 INFO 140277027632960] #quality_metric: host=algo-1, epoch=35, validation mAP <score>=(0.020909951656857096)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:55 INFO 140277027632960] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 36, \"sum\": 36.0, \"min\": 36}}, \"EndTime\": 1568180395.810608, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 35}, \"StartTime\": 1568180394.205565}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:57 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:57 INFO 140277027632960] #quality_metric: host=algo-1, epoch=36, batch=10 train cross_entropy <loss>=(0.7494314819012048)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:57 INFO 140277027632960] #quality_metric: host=algo-1, epoch=36, batch=10 train smooth_l1 <loss>=(0.8908823436161257)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:57 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:57 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:57 INFO 140277027632960] #quality_metric: host=algo-1, epoch=36, validation mAP <score>=(0.021428719669626988)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:57 INFO 140277027632960] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 37, \"sum\": 37.0, \"min\": 37}}, \"EndTime\": 1568180397.626174, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 36}, \"StartTime\": 1568180395.810849}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:58 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:58 INFO 140277027632960] #quality_metric: host=algo-1, epoch=37, batch=9 train cross_entropy <loss>=(0.7388141990578088)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:58 INFO 140277027632960] #quality_metric: host=algo-1, epoch=37, batch=9 train smooth_l1 <loss>=(0.8566244640489564)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:58 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:58 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:59 INFO 140277027632960] #quality_metric: host=algo-1, epoch=37, validation mAP <score>=(0.02735237865747687)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:39:59 INFO 140277027632960] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 38, \"sum\": 38.0, \"min\": 38}}, \"EndTime\": 1568180399.187604, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 37}, \"StartTime\": 1568180397.626597}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[09/11/2019 05:40:00 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:00 INFO 140277027632960] #quality_metric: host=algo-1, epoch=38, batch=10 train cross_entropy <loss>=(0.7530057083847176)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:00 INFO 140277027632960] #quality_metric: host=algo-1, epoch=38, batch=10 train smooth_l1 <loss>=(0.8252594185690595)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:00 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:00 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:01 INFO 140277027632960] #quality_metric: host=algo-1, epoch=38, validation mAP <score>=(0.029008919811766672)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:01 INFO 140277027632960] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 39, \"sum\": 39.0, \"min\": 39}}, \"EndTime\": 1568180401.031273, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 38}, \"StartTime\": 1568180399.18807}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:02 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:02 INFO 140277027632960] #quality_metric: host=algo-1, epoch=39, batch=9 train cross_entropy <loss>=(0.7445003018520846)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:02 INFO 140277027632960] #quality_metric: host=algo-1, epoch=39, batch=9 train smooth_l1 <loss>=(0.9075503561756398)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:02 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:02 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:02 INFO 140277027632960] #quality_metric: host=algo-1, epoch=39, validation mAP <score>=(0.024064150398027184)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:02 INFO 140277027632960] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 40, \"sum\": 40.0, \"min\": 40}}, \"EndTime\": 1568180402.661652, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 39}, \"StartTime\": 1568180401.03202}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:03 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:03 INFO 140277027632960] #quality_metric: host=algo-1, epoch=40, batch=10 train cross_entropy <loss>=(0.7325853941932557)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:04 INFO 140277027632960] #quality_metric: host=algo-1, epoch=40, batch=10 train smooth_l1 <loss>=(0.7757884680278717)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:04 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:04 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:04 INFO 140277027632960] #quality_metric: host=algo-1, epoch=40, validation mAP <score>=(0.013207545003755447)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:04 INFO 140277027632960] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 41, \"sum\": 41.0, \"min\": 41}}, \"EndTime\": 1568180404.519567, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 40}, \"StartTime\": 1568180402.662073}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:05 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:05 INFO 140277027632960] #quality_metric: host=algo-1, epoch=41, batch=9 train cross_entropy <loss>=(0.7385622999247383)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:05 INFO 140277027632960] #quality_metric: host=algo-1, epoch=41, batch=9 train smooth_l1 <loss>=(0.8912114325691672)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:05 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:05 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:06 INFO 140277027632960] #quality_metric: host=algo-1, epoch=41, validation mAP <score>=(0.02044660807601734)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:06 INFO 140277027632960] #progress_metric: host=algo-1, completed 84 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 42, \"sum\": 42.0, \"min\": 42}}, \"EndTime\": 1568180406.133684, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 41}, \"StartTime\": 1568180404.519856}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:07 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:07 INFO 140277027632960] #quality_metric: host=algo-1, epoch=42, batch=10 train cross_entropy <loss>=(0.7243770942687988)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:07 INFO 140277027632960] #quality_metric: host=algo-1, epoch=42, batch=10 train smooth_l1 <loss>=(0.8960122013092041)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:07 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:07 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:08 INFO 140277027632960] #quality_metric: host=algo-1, epoch=42, validation mAP <score>=(0.0108305588904473)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:08 INFO 140277027632960] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 43, \"sum\": 43.0, \"min\": 43}}, \"EndTime\": 1568180408.033483, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 42}, \"StartTime\": 1568180406.133931}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:09 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:09 INFO 140277027632960] #quality_metric: host=algo-1, epoch=43, batch=9 train cross_entropy <loss>=(0.7425849659968231)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:09 INFO 140277027632960] #quality_metric: host=algo-1, epoch=43, batch=9 train smooth_l1 <loss>=(0.7423637640678277)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:09 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:09 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:09 INFO 140277027632960] #quality_metric: host=algo-1, epoch=43, validation mAP <score>=(0.01909142249600246)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:09 INFO 140277027632960] #progress_metric: host=algo-1, completed 88 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 44, \"sum\": 44.0, \"min\": 44}}, \"EndTime\": 1568180409.608538, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 43}, \"StartTime\": 1568180408.033693}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-09-11 05:40:22 Uploading - Uploading generated training model"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[09/11/2019 05:40:10 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:10 INFO 140277027632960] #quality_metric: host=algo-1, epoch=44, batch=10 train cross_entropy <loss>=(0.7405127572341704)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:10 INFO 140277027632960] #quality_metric: host=algo-1, epoch=44, batch=10 train smooth_l1 <loss>=(0.8364117917880206)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:10 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:11 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:11 INFO 140277027632960] #quality_metric: host=algo-1, epoch=44, validation mAP <score>=(0.01968443735513238)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:11 INFO 140277027632960] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}}, \"EndTime\": 1568180411.394986, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 44}, \"StartTime\": 1568180409.608849}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:12 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:12 INFO 140277027632960] #quality_metric: host=algo-1, epoch=45, batch=9 train cross_entropy <loss>=(0.7303529042823642)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:12 INFO 140277027632960] #quality_metric: host=algo-1, epoch=45, batch=9 train smooth_l1 <loss>=(0.8518826681024888)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:12 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:12 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:13 INFO 140277027632960] #quality_metric: host=algo-1, epoch=45, validation mAP <score>=(0.01622039422041156)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:13 INFO 140277027632960] #progress_metric: host=algo-1, completed 92 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 46, \"sum\": 46.0, \"min\": 46}}, \"EndTime\": 1568180413.030393, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 45}, \"StartTime\": 1568180411.396307}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:14 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:14 INFO 140277027632960] #quality_metric: host=algo-1, epoch=46, batch=10 train cross_entropy <loss>=(0.7177330372380275)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:14 INFO 140277027632960] #quality_metric: host=algo-1, epoch=46, batch=10 train smooth_l1 <loss>=(0.8281089044084736)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:14 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:14 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:14 INFO 140277027632960] #quality_metric: host=algo-1, epoch=46, validation mAP <score>=(0.013601165935359285)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:14 INFO 140277027632960] #progress_metric: host=algo-1, completed 94 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 47, \"sum\": 47.0, \"min\": 47}}, \"EndTime\": 1568180414.873949, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 46}, \"StartTime\": 1568180413.030615}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:15 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:15 INFO 140277027632960] #quality_metric: host=algo-1, epoch=47, batch=9 train cross_entropy <loss>=(0.7322337005449377)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:15 INFO 140277027632960] #quality_metric: host=algo-1, epoch=47, batch=9 train smooth_l1 <loss>=(0.8225828751273777)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:15 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:16 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:16 INFO 140277027632960] #quality_metric: host=algo-1, epoch=47, validation mAP <score>=(0.02427599069414229)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:16 INFO 140277027632960] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 48, \"sum\": 48.0, \"min\": 48}}, \"EndTime\": 1568180416.47348, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 47}, \"StartTime\": 1568180414.874236}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:17 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 10. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:17 INFO 140277027632960] #quality_metric: host=algo-1, epoch=48, batch=10 train cross_entropy <loss>=(0.7408765082557996)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:17 INFO 140277027632960] #quality_metric: host=algo-1, epoch=48, batch=10 train smooth_l1 <loss>=(0.928045262893041)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:17 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:17 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:18 INFO 140277027632960] #quality_metric: host=algo-1, epoch=48, validation mAP <score>=(0.03442623409542726)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:18 INFO 140277027632960] #progress_metric: host=algo-1, completed 98 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 49, \"sum\": 49.0, \"min\": 49}}, \"EndTime\": 1568180418.295037, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 48}, \"StartTime\": 1568180416.474152}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:19 WARNING 140277027632960] Expected number of batches: 8275, did not match the number of batches processed: 9. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:19 INFO 140277027632960] #quality_metric: host=algo-1, epoch=49, batch=9 train cross_entropy <loss>=(0.7312443758312025)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:19 INFO 140277027632960] #quality_metric: host=algo-1, epoch=49, batch=9 train smooth_l1 <loss>=(0.8260987055929083)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:19 INFO 140277027632960] Round of batches complete\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:19 INFO 140277027632960] Updated the metrics\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:19 INFO 140277027632960] #quality_metric: host=algo-1, epoch=49, validation mAP <score>=(0.032716157345859906)\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:19 INFO 140277027632960] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 50, \"sum\": 50.0, \"min\": 50}}, \"EndTime\": 1568180419.883556, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 49}, \"StartTime\": 1568180418.295329}\n",
      "\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:19 WARNING 140277027632960] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[09/11/2019 05:40:20 INFO 140277027632960] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[31m[09/11/2019 05:40:20 INFO 140277027632960] Test data is not provided.\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 50, \"sum\": 50.0, \"min\": 50}, \"totaltime\": {\"count\": 1, \"max\": 102302.70314216614, \"sum\": 102302.70314216614, \"min\": 102302.70314216614}, \"setuptime\": {\"count\": 1, \"max\": 12.18414306640625, \"sum\": 12.18414306640625, \"min\": 12.18414306640625}}, \"EndTime\": 1568180420.083149, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\"}, \"StartTime\": 1568180317.861361}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-09-11 05:40:43 Completed - Training job completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training seconds: 203\n",
      "Billable seconds: 203\n"
     ]
    }
   ],
   "source": [
    "s3_train_data = 's3://{}/{}'.format(sage_bucket, my_bucket+'/train/')\n",
    "s3_validation_data = 's3://{}/{}'.format(sage_bucket, my_bucket+'/validation/')\n",
    "\n",
    "s3_output_location = 's3://{}/{}/output'.format(sage_bucket, my_bucket)\n",
    "\n",
    "od_model = sagemaker.estimator.Estimator(training_image,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.p2.xlarge',\n",
    "                                         train_volume_size = 50,\n",
    "                                         train_max_run = 360000,\n",
    "                                         input_mode= 'File',\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sess)\n",
    "                                         \n",
    "od_model.set_hyperparameters(base_network=network,\n",
    "                             use_pretrained_model=1,\n",
    "                             num_classes=nclass,\n",
    "                             mini_batch_size=mini_batch_size,\n",
    "                             epochs=epochs,\n",
    "                             learning_rate=lr,\n",
    "                             lr_scheduler_step='3,6',\n",
    "                             lr_scheduler_factor=lr_scheduler_factor,\n",
    "                             optimizer=optim,\n",
    "                             momentum=momentum,\n",
    "                             weight_decay=weight_decay,\n",
    "                             overlap_threshold=overlap,\n",
    "                             nms_threshold=nms_thresh,\n",
    "                             image_shape=image_shape,   \n",
    "                             label_width=label_width,\t\t\n",
    "                             num_training_samples=n_train_samples)\n",
    "\n",
    "train_data = sagemaker.session.s3_input(s3_train_data, distribution='FullyReplicated', \n",
    "                        content_type='application/x-recordio', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.session.s3_input(s3_validation_data, distribution='FullyReplicated', \n",
    "                             content_type='application/x-recordio', s3_data_type='S3Prefix')\n",
    "data_channels = {'train': train_data, 'validation': validation_data}\n",
    "od_model.fit(inputs=data_channels, logs=True)    \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.078985,
     "end_time": "2019-09-11T05:41:09.796023",
     "exception": false,
     "start_time": "2019-09-11T05:41:09.717038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So now you are training!!! This will take a little while. We are only training for a very small number of epochs (2!), so we don't expect to have a really robust model. Potentially many 100s of epochs may be required depeneding on the quality and amount of training data we have. \n",
    "\n",
    "To level set, this model will be CRAPPY. But that is ok. You now have the basic tools required to set up and improve upon your own problem.\n",
    "\n",
    "ðŸ¤” What are the big considerations as a data scientist?\n",
    "\n",
    "ðŸ¤” What could we do to improve our model?\n",
    "\n",
    "ðŸ¤” How could we evaluate the quality of our data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 489.665596,
     "end_time": "2019-09-11T05:49:19.513086",
     "exception": false,
     "start_time": "2019-09-11T05:41:09.847490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!"
     ]
    }
   ],
   "source": [
    "object_detector = od_model.deploy(initial_instance_count = 1,instance_type = 'ml.m4.xlarge')   \n",
    "\n",
    "#response = object_detector.predict(data)\n",
    "\n",
    "# Tears down the SageMaker endpoint and endpoint configuration\n",
    "#object_detector.delete_endpoint()\n",
    "\n",
    "# Deletes the SageMaker model\n",
    "#object_detector.delete_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.067211,
     "end_time": "2019-09-11T05:49:19.639880",
     "exception": false,
     "start_time": "2019-09-11T05:49:19.572669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Outside of this notebook, you can investigate your endpoint in the sagemaker console and run the test.sh script with the appropriate aws keys/role. This will generate some stats.\n",
    "\n",
    "You can also edit the output in the 'endpoint_infer_slippygeo.py' to write out a geojson that you can then explore in QGIS, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.049101,
     "end_time": "2019-09-11T05:49:19.754584",
     "exception": false,
     "start_time": "2019-09-11T05:49:19.705483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "papermill": {
   "duration": 873.150806,
   "end_time": "2019-09-11T05:49:20.570375",
   "environment_variables": {},
   "exception": null,
   "input_path": "osm_ml_training_pt2.ipynb",
   "output_path": "osm_ml_training_pt2_out.ipynb",
   "parameters": {
    "ACCESS_KEY": "AKIAZOSGCRJY5YOTSRPR",
    "SECRET_KEY": "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",
    "my_bucket": "team_echidna",
    "role": "arn:aws:iam::649760770673:role/service-role/AmazonSageMaker-ExecutionRole-20190910T173949",
    "sage_bucket": "eagleview-data"
   },
   "start_time": "2019-09-11T05:34:47.419569",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}